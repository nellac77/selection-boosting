# selection-boosting
A look into how to select appropriate ML models and XGBoost

## In this repository we will use:
+ k-Fold Cross Validation
+ Grid Search

in order to address the follwoing questions:
+ How do I handle the bias-variance tradeoff when traiing a model and its performance evaluation?
+ How can I choose the most optimal values for parameters that are not learned ("hyperparameters")?
+ What ML model is appropriate for solving my problem?

### Also... XGBoost
A  powerful ML model. Let's see what it can do.
